{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fifty-roberts",
   "metadata": {},
   "source": [
    "# The AR Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-oliver",
   "metadata": {},
   "source": [
    "## Listing 3-1. Describing a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import the dataframe\n",
    "eq = pd.read_csv('Ch03_Earthquake_database.csv')\n",
    "\n",
    "# Describe the dataframe\n",
    "eq.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-technician",
   "metadata": {},
   "source": [
    "## Listing 3-2. Profiling a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-america",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pandas profiling package\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "# Get the pandas profiling report\n",
    "eq.profile_report()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-prime",
   "metadata": {},
   "source": [
    "## Listing 3-3. Convert the earthquake data to the yearly number of earthquake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Only keep \n",
    "eq['Date'] = eq['Date'].str[0:10]\n",
    "\n",
    "# Convert years to dates\n",
    "eq['year'] = pd.to_datetime(eq['Date']).dt.year\n",
    "\n",
    "# Filter on earthquakes with magnitude of 7 or higher\n",
    "eq = eq[eq['Magnitude'] >= 7]\n",
    "\n",
    "# Compute a count of earthquakes per year\n",
    "earthquakes_per_year = eq.groupby('year').count()\n",
    "\n",
    "# Remove erroneous values for year\n",
    "earthquakes_per_year = earthquakes_per_year.iloc[1:-2, 0]\n",
    "\n",
    "# Make a plot of earthquakes per year\n",
    "ax = earthquakes_per_year.plot()\n",
    "ax.set_ylabel(\"Number of Earthquakes\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-economy",
   "metadata": {},
   "source": [
    "## Listing 3-4. Convert the earthquake data to the yearly number of earthquake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-radical",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifts = pd.DataFrame(\n",
    "    {\n",
    "        'this year': earthquakes_per_year,\n",
    "        'past year': earthquakes_per_year.shift(1)\n",
    "    }\n",
    ")\n",
    "\n",
    "ax = shifts.plot()\n",
    "ax.set_ylabel('Number of Earthquakes')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-beach",
   "metadata": {},
   "source": [
    "## Listing 3-5. Drop missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-present",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifts = shifts.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-collective",
   "metadata": {},
   "source": [
    "## Listing 3-6. Compute a correlation matrix for the shifts dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifts.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-unemployment",
   "metadata": {},
   "source": [
    "## Listing 3-7. Augmented Dicky Fuller test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-publication",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "result = adfuller(earthquakes_per_year.dropna())\n",
    "print(result)\n",
    "\n",
    "pvalue = result[1]\n",
    "if pvalue < 0.05:\n",
    "    print('stationary')\n",
    "else:\n",
    "    print('not stationary')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-fifteen",
   "metadata": {},
   "source": [
    "## Listing 3-8. Differencing in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference the data\n",
    "differenced_data = earthquakes_per_year.diff().dropna()\n",
    "\n",
    "# Plot the differenced data\n",
    "ax = differenced_data.plot()\n",
    "ax.set_ylabel('Differenced number of Earthquakes')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-mirror",
   "metadata": {},
   "source": [
    "## Listing 3-9. Autocorrelation of the differenced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-cable",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifts_diff = pd.DataFrame(\n",
    "    {\n",
    "        'this year': differenced_data,\n",
    "        'past year': differenced_data.shift(1)\n",
    "    }\n",
    ")\n",
    "\n",
    "ax = shifts_diff.plot()\n",
    "ax.set_ylabel('Differenced number of Earthquakes')\n",
    "plt.show()\n",
    "\n",
    "shifts_diff.corr()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-captain",
   "metadata": {},
   "source": [
    "## Listing 3-10. Autocorrelation of the differenced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_acf(differenced_data, lags=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-quarter",
   "metadata": {},
   "source": [
    "## Listing 3-11. Autocorrelation of the differenced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-missouri",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "plot_pacf(differenced_data, lags = 20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-chaos",
   "metadata": {},
   "source": [
    "## Listing 3-12. Estimate Yule Walker AR coefficients with order 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-determination",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.regression.linear_model import yule_walker\n",
    "coefficients, sigma = yule_walker(differenced_data, order = 3)\n",
    "print('coefficients: ', -coefficients)\n",
    "print('sigma: ', sigma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-export",
   "metadata": {},
   "source": [
    "## Listing 3-13. Make a Forecast with the AR coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients, sigma = yule_walker(differenced_data, order = 3)\n",
    "\n",
    "# Make a list of differenced values\n",
    "val_list = list(differenced_data)\n",
    "# Reverse the list so that the order corresponds with the order of the coefficients\n",
    "val_list.reverse()\n",
    "# Define the number of years to predict\n",
    "n_steps = 10\n",
    "\n",
    "# For each year to predict\n",
    "for i in range(n_steps):\n",
    "    \n",
    "    # Compute the new value as the sum of lagged values multiplied by their corresponding coefficient\n",
    "    new_val = 0\n",
    "    for j in range(len(coefficients)):\n",
    "        \n",
    "        new_val += coefficients[j] * val_list[j]\n",
    "    \n",
    "    # Insert the new value at the beginning of the list\n",
    "    val_list.insert(0, new_val)\n",
    "\n",
    "# Redo the reverse to have the order of time\n",
    "val_list.reverse()\n",
    "\n",
    "# Add the original first value back into the list and do a cumulative sum to undo the differencing \n",
    "val_list = [earthquakes_per_year.values[0]] + val_list\n",
    "new_val_list = pd.Series(val_list).cumsum()\n",
    "\n",
    "# Plot the newly obtained list\n",
    "plt.plot(range(1966, 2025), new_val_list)\n",
    "plt.ylabel('Number of earthquakes')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-glance",
   "metadata": {},
   "source": [
    "## Listing 3-14. Fit the model on a train set and evaluate it on a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-aspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "train = list(differenced_data)[:-10]\n",
    "test = list(earthquakes_per_year)[-10:]\n",
    "\n",
    "coefficients, sigma = yule_walker(train, order = 3)\n",
    "\n",
    "# Make a list of differenced values\n",
    "val_list = list(train)\n",
    "# Reverse the list so that the order corresponds with the order of the coefficients\n",
    "val_list.reverse()\n",
    "# Define the number of years to predict\n",
    "n_steps = 10\n",
    "\n",
    "# For each year to predict\n",
    "for i in range(n_steps):\n",
    "    \n",
    "    # Compute the new value as the sum of lagged values multiplied by their corresponding coefficient\n",
    "    new_val = 0\n",
    "    for j in range(len(coefficients)):\n",
    "        \n",
    "        new_val += coefficients[j] * val_list[j]\n",
    "    \n",
    "    # Insert the new value at the beginning of the list\n",
    "    val_list.insert(0, new_val)\n",
    "\n",
    "# Redo the reverso to have the order of time\n",
    "val_list.reverse()\n",
    "\n",
    "# Add the original first value back into the list and do a cumulative sum to undo the differencing \n",
    "val_list = [earthquakes_per_year[0]] + val_list\n",
    "new_val_list = pd.Series(val_list).cumsum()\n",
    "\n",
    "# Plot the newly obtained list\n",
    "validation = pd.DataFrame({\n",
    "    'original': earthquakes_per_year.reset_index(drop=True),\n",
    "    'pred': new_val_list })\n",
    "\n",
    "print('Test R2:', r2_score(validation.iloc[-10:, 0], validation.iloc[-10:, 1]))\n",
    "\n",
    "# Plot the newly obtained list\n",
    "plt.plot(range(1966, 2015), validation)\n",
    "plt.legend(validation.columns)\n",
    "plt.ylabel('Number of earthquakes')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-appearance",
   "metadata": {},
   "source": [
    "## Listing 3-15. Apply a grid search to find the order that gives the best R2 score on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-cambodia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(order):\n",
    "    train = list(differenced_data)[:-10]\n",
    "    test = list(earthquakes_per_year)[-10:]\n",
    "\n",
    "    coefficients, sigma = yule_walker(train, order = order)\n",
    "\n",
    "    # Make a list of differenced values\n",
    "    val_list = list(train)\n",
    "    # Reverse the list to corresponds with the order of coefs\n",
    "    val_list.reverse()\n",
    "    # Define the number of years to predict\n",
    "    n_steps = 10\n",
    "\n",
    "    # For each year to predict\n",
    "    for i in range(n_steps):\n",
    "\n",
    "        # Compute the new value \n",
    "        new_val = 0\n",
    "        for j in range(len(coefficients)):\n",
    "            new_val += coefficients[j] * val_list[j]\n",
    "\n",
    "        # Insert the new value at the beginning of the list\n",
    "        val_list.insert(0, new_val)\n",
    "\n",
    "    # Redo the reverse to have the order of time\n",
    "    val_list.reverse()\n",
    "\n",
    "    # Undo the differencing with a cumsum\n",
    "    val_list = [earthquakes_per_year[0]] + val_list\n",
    "    new_val_list = pd.Series(val_list).cumsum()\n",
    "\n",
    "    # Plot the newly obtained list\n",
    "    validation = pd.DataFrame({\n",
    "        'original': earthquakes_per_year.reset_index(drop=True),\n",
    "        'pred': new_val_list })\n",
    "\n",
    "    return r2_score(validation.iloc[-10:, 0], validation.iloc[-10:, 1])\n",
    "\n",
    "# For each order between 1 and 30, fit and evaluate the model\n",
    "orders = []\n",
    "r2scores = []\n",
    "for order in range(1, 31):\n",
    "    orders.append(order)\n",
    "    r2scores.append(evaluate(order))\n",
    "    \n",
    "# Create a results data frame\n",
    "results =pd.DataFrame({'orders': orders,\n",
    "                      'scores': r2scores})\n",
    "\n",
    "# Show the order with best R2 score\n",
    "results[results['scores'] == results.max()['scores']]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
