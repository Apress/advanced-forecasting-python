{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "soviet-cameroon",
   "metadata": {},
   "source": [
    "# Chapter 02 - Model Evaluation for Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-admission",
   "metadata": {},
   "source": [
    "## Listing 2-1.Getting the stock data example into Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-visit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "period = ['Januray', 'February', 'March',\n",
    "         'April', 'May', 'June',\n",
    "         'July', 'August', 'September',\n",
    "         'October', 'November', 'December']\n",
    "\n",
    "actual = [35, 35, 10, \n",
    "          5, 8, 10, \n",
    "          15, 20, 23, \n",
    "          21, 22, 25]\n",
    "\n",
    "forecast = [30, 31, 30, \n",
    "              10, 12, 17, \n",
    "              18, 27, 29, \n",
    "              24, 23, 22]\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'period': period,\n",
    "    'actual': actual,\n",
    "    'forecast': forecast\n",
    "})\n",
    "\n",
    "ax = data.plot.line(x='period')\n",
    "ax.set_title('Forecast vs Actual', fontsize=16)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-feedback",
   "metadata": {},
   "source": [
    "## Listing 2-2. Computing the Mean Squared Error in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print(mean_squared_error(data['actual'], data['forecast']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-space",
   "metadata": {},
   "source": [
    "## Listing 2-3. Computing the Root Mean Squared Error in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-picnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "print(sqrt(mean_squared_error(data['actual'], data['forecast'])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-colorado",
   "metadata": {},
   "source": [
    "## Listing 2-5.Computing the Mean Absolute Error in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-border",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "print(mean_absolute_error(data['actual'], data['forecast']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-feeling",
   "metadata": {},
   "source": [
    "## Listing 2-6. Computing the Mean Absolute Percent Error in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(mean_absolute_percentage_error(data['actual'], data['forecast']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-intention",
   "metadata": {},
   "source": [
    "## Listing 2-4. Computing the R2 in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-advertising",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(data['actual'], data['forecast'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-consolidation",
   "metadata": {},
   "source": [
    "## Listing 2-7. Train Test Split in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-intake",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = data['actual']\n",
    "train, test = train_test_split(y, test_size=0.3, shuffle=False)\n",
    "forecast = train.mean() # forecast is 17.25\n",
    "train = pd.DataFrame(train)\n",
    "train['forecast'] = forecast\n",
    "train_error = mean_squared_error(train['actual'], train['forecast'])\n",
    "\n",
    "test = pd.DataFrame(test)\n",
    "test['forecast'] = forecast\n",
    "test_error = mean_squared_error(test['actual'], test['forecast'])\n",
    "print(train_error, test_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-visit",
   "metadata": {},
   "source": [
    "## Listing 2-8. Train Validation Test Split in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-saying",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into 70% train, 15% validation and 15% test\n",
    "train, test = train_test_split(data['actual'], test_size = 0.3, shuffle = False, random_state=12345)\n",
    "val, test = train_test_split(test, test_size = 0.5, shuffle = False, random_state=12345)\n",
    "\n",
    "# Fit (estimate) the two models on the train data\n",
    "forecast_mean = train.mean() # 17.25\n",
    "forecast_median = train.median() # 12.5\n",
    "\n",
    "# Compute MSE on validation data for both models\n",
    "val = pd.DataFrame(val)\n",
    "\n",
    "val['forecast_mean'] = forecast_mean\n",
    "val['forecast_median'] = forecast_median\n",
    "\n",
    "mean_val_mse = mean_squared_error(val['actual'], val['forecast_mean'])\n",
    "median_val_mse = mean_squared_error(val['actual'], val['forecast_median'])\n",
    "\n",
    "# You observe the following validation mse: mean mse: 23.56, median mse: 91.25\n",
    "print(mean_val_mse, median_val_mse) \n",
    "\n",
    "# The best performance is the mean model, so verify its error on test data\n",
    "test = pd.DataFrame(test)\n",
    "test['forecast_mean'] = forecast_mean\n",
    "\n",
    "mean_test_mse = mean_squared_error(test['actual'], test['forecast_mean'])\n",
    "\n",
    "# You observe a test mse of 41.3125, almost double the validation mse\n",
    "print(mean_test_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-evening",
   "metadata": {},
   "source": [
    "## Listing 2-9. K-fold cross-validation in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-backup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "errors = []\n",
    "for train_index, test_index in kf.split(data):\n",
    "    train = data.iloc[train_index,:]\n",
    "    test = data.iloc[test_index,:]\n",
    "    \n",
    "    pred = train['actual'].mean()\n",
    "    test['forecast'] = pred\n",
    "    error = mean_squared_error(test['actual'], test['forecast'])\n",
    "    errors.append(error)\n",
    "\n",
    "print(np.mean(errors))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-emerald",
   "metadata": {},
   "source": [
    "## Listing 2-10. Time Series Cross-Valdiation in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-hacker",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit()\n",
    "\n",
    "errors = []\n",
    "for train_index, test_index in tscv.split(data):\n",
    "    train = data.iloc[train_index,:]\n",
    "    test = data.iloc[test_index,:]\n",
    "    pred = train['actual'].mean()\n",
    "    test['forecast'] = pred\n",
    "    error = mean_squared_error(test['actual'], test['forecast'])\n",
    "    errors.append(error)\n",
    "    \n",
    "print(np.mean(errors))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guided-penguin",
   "metadata": {},
   "source": [
    "## Listing 2-11 Rolling Time Series Cross-Valdiation in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(max_train_size = 2)\n",
    "\n",
    "errors = []\n",
    "for train_index, test_index in tscv.split(data):\n",
    "    train = data.iloc[train_index,:]\n",
    "    test = data.iloc[test_index,:]\n",
    "    \n",
    "    pred = train['actual'].mean()\n",
    "    test['forecast'] = pred\n",
    "    error = mean_squared_error(test['actual'], test['forecast'])\n",
    "    errors.append(error)\n",
    "    \n",
    "print(np.mean(errors))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
