{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "solved-surge",
   "metadata": {},
   "source": [
    "# Chapter 14 - The Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-hazard",
   "metadata": {},
   "source": [
    "## Listing 14-1. Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-mainstream",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('Ch05_Sunspots_database.csv')\n",
    "data = data.iloc[:,[1,2]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-advice",
   "metadata": {},
   "source": [
    "## Listing 14-2. Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-accountability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonality variables\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data['Year'] = data['Date'].apply(lambda x: x.year)\n",
    "data['Month'] = data['Date'].apply(lambda x: x.month)\n",
    "\n",
    "# Adding a year of lagged data\n",
    "data['L1'] = data['Monthly Mean Total Sunspot Number'].shift(1)\n",
    "data['L2'] = data['Monthly Mean Total Sunspot Number'].shift(2)\n",
    "data['L3'] = data['Monthly Mean Total Sunspot Number'].shift(3)\n",
    "data['L4'] = data['Monthly Mean Total Sunspot Number'].shift(4)\n",
    "data['L5'] = data['Monthly Mean Total Sunspot Number'].shift(5)\n",
    "data['L6'] = data['Monthly Mean Total Sunspot Number'].shift(6)\n",
    "data['L7'] = data['Monthly Mean Total Sunspot Number'].shift(7)\n",
    "data['L8'] = data['Monthly Mean Total Sunspot Number'].shift(8)\n",
    "data['L9'] = data['Monthly Mean Total Sunspot Number'].shift(9)\n",
    "data['L10'] = data['Monthly Mean Total Sunspot Number'].shift(10)\n",
    "data['L11'] = data['Monthly Mean Total Sunspot Number'].shift(11)\n",
    "data['L12'] = data['Monthly Mean Total Sunspot Number'].shift(12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-proposition",
   "metadata": {},
   "source": [
    "## Listing 14-3. Fitting the default Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y object\n",
    "data = data.dropna()\n",
    "y = data['Monthly Mean Total Sunspot Number']\n",
    "X = data[['Year', 'Month', 'L1', 'L2', 'L3', 'L4', 'L5', 'L6', 'L7', 'L8', 'L9', 'L10', 'L11', 'L12']]\n",
    "\n",
    "# Create Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=12345, shuffle=False)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "my_rf = RandomForestRegressor()\n",
    "my_rf.fit(X_train, y_train)\n",
    "fcst = my_rf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(list(y_test), list(fcst))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-factor",
   "metadata": {},
   "source": [
    "## Listing 14-4. Fitting the Random Forest Regressor with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-prison",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "my_rf = GridSearchCV(RandomForestRegressor(), \n",
    "                 {'max_features':[0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95],\n",
    "                 'n_estimators': [10, 50, 100, 250, 500, 750, 1000]},\n",
    "                scoring = 'r2', n_jobs = -1)\n",
    "\n",
    "my_rf.fit(X_train, y_train)\n",
    "print(r2_score(list(y_test), list(my_rf.predict(X_test))))\n",
    "print(my_rf.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-health",
   "metadata": {},
   "source": [
    "## Listing 14-5. Obtaining the plot of the forecast on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(list(fcst))\n",
    "plt.plot(list(y_test))\n",
    "plt.legend(['fcst', 'actu'])\n",
    "plt.ylabel('Sunspots')\n",
    "plt.xlabel('Steps into the test data')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-wound",
   "metadata": {},
   "source": [
    "## Listing 14-6. Testing out a normal distribution for the max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-satellite",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "\n",
    "mu = 0.8\n",
    "variance = 0.005\n",
    "sigma = math.sqrt(variance)\n",
    "x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n",
    "plt.plot(x, stats.norm.pdf(x, mu, sigma))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-egypt",
   "metadata": {},
   "source": [
    "## Listing 14-7. Testing out a uniform distribution for the n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 2000, 100)\n",
    "plt.plot(x, stats.uniform.pdf(x, 50, 950))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-consumption",
   "metadata": {},
   "source": [
    "## Listing 14-8. RandomizedSearchCv with two distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Specifying the distributions to draw from\n",
    "distributions = {\n",
    "    'max_features': stats.norm(0.8, math.sqrt(0.005)),\n",
    "    'n_estimators': stats.randint(50, 1000)\n",
    "}\n",
    "\n",
    "# Creating the search\n",
    "my_rf = RandomizedSearchCV(RandomForestRegressor(),\n",
    "                           \n",
    "                     distributions, n_iter=10,\n",
    "                          scoring = 'r2',\n",
    "                          n_jobs = -1,\n",
    "                          random_state = 12345)\n",
    "\n",
    "# Fitting the search\n",
    "my_rf.fit(X_train, y_train)\n",
    "\n",
    "# Printing the results\n",
    "print(r2_score(list(y_test), list(my_rf.predict(X_test))))\n",
    "print(my_rf.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-ottawa",
   "metadata": {},
   "source": [
    "## Listing 14-9.Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.DataFrame({\n",
    "        'feature': X_train.columns,\n",
    "        'importance': my_rf.best_estimator_.feature_importances_})\n",
    "\n",
    "fi.sort_values('importance', ascending=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
