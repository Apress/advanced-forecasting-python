{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "wireless-victim",
   "metadata": {},
   "source": [
    "# Chapter 15 - Gradient Boosting with XGBoost and LigthGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-ivory",
   "metadata": {},
   "source": [
    "## Listing 15-1. Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-tampa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('Metro_Interstate_Traffic_Volume.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-legislation",
   "metadata": {},
   "source": [
    "## Listing 15-2. Applying the same feature engineering as done previously for the kNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['year'] = data['date_time'].apply(lambda x: int(x[:4]))\n",
    "data['month'] = data['date_time'].apply(lambda x: int(x[5:7]))\n",
    "data['weekday'] = pd.to_datetime(data['date_time']).apply(lambda x: x.weekday())\n",
    "data['hour'] = pd.to_datetime(data['date_time']).apply(lambda x: x.hour)\n",
    "data['isholiday'] = (data['holiday'] == 'None').apply(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-coffee",
   "metadata": {},
   "source": [
    "## Listing 15-3. Applying the default XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-efficiency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create objects X and y\n",
    "X = data[['year', 'month', 'weekday', 'hour', 'isholiday']]\n",
    "y = data['traffic_volume']\n",
    "\n",
    "# Create Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=100, random_state=12345, shuffle=False)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "my_xgb = XGBRegressor()\n",
    "my_xgb.fit(X_train, y_train)\n",
    "\n",
    "xgb_fcst = my_xgb.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "print(r2_score(list(y_test), list(xgb_fcst)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-maintenance",
   "metadata": {},
   "source": [
    "## Listing 15-4. Applying the default LightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "my_lgbm = LGBMRegressor()\n",
    "my_lgbm.fit(X_train, y_train)\n",
    "\n",
    "lgbm_fcst = my_lgbm.predict(X_test)\n",
    "\n",
    "print(r2_score(list(y_test), list(lgbm_fcst)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-darwin",
   "metadata": {},
   "source": [
    "## Listing 15-5. Create a graph to compare the XGBoost and LightGBM forecast to the actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-devices",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(list(y_test))\n",
    "plt.plot(list(xgb_fcst))\n",
    "plt.plot(list(lgbm_fcst))\n",
    "plt.legend(['actual', 'xgb forecast', 'lgbm forecast'])\n",
    "plt.ylabel('Traffic Volume')\n",
    "plt.xlabel('Steps in test data')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-polyester",
   "metadata": {},
   "source": [
    "## Listing 15-4. Applying a Bayesian Optimization to the xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "xgb_opt = BayesSearchCV(\n",
    "    XGBRegressor(),\n",
    "    {\n",
    "        'learning_rate': (10e-6, 1.0, 'log-uniform'),\n",
    "        'max_depth': Integer(0, 50, 'uniform'),\n",
    "        'n_estimators' : (10, 1000, 'log-uniform'),\n",
    "    },\n",
    "    n_iter=10,\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "xgb_opt.fit(X_train, y_train)\n",
    "xgb_tuned_fcst = opt.best_estimator_.predict(X_test)\n",
    "r2_score(list(y_test), list(xgb_tuned_fcst))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-prize",
   "metadata": {},
   "source": [
    "## Listing 15-5. Applying a Bayesian Optimization to the LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-advance",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "lgbm_opt = BayesSearchCV(\n",
    "    LGBMRegressor(),\n",
    "    {\n",
    "        'learning_rate': (10e-6, 1.0, 'log-uniform'),\n",
    "        'max_depth': Integer(-1, 50, 'uniform'),\n",
    "        'n_estimators' : (10, 1000, 'log-uniform'),\n",
    "    },\n",
    "    n_iter=10,\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "lgbm_opt.fit(X_train, y_train)\n",
    "\n",
    "lgbm_tuned_fcst = lgbm_opt.best_estimator_.predict(X_test)\n",
    "r2_score(list(y_test), list(lgbm_tuned_fcst))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-anaheim",
   "metadata": {},
   "source": [
    "## Listing 15-6. Plotting the two tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(list(y_test))\n",
    "plt.plot(list(xgb_tuned_fcst))\n",
    "plt.plot(list(lgbm_tuned_fcst))\n",
    "plt.legend(['actual', 'xgb forecast', 'lgbm forecast'])\n",
    "plt.ylabel('Traffic Volume')\n",
    "plt.xlabel('Steps in test data')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
