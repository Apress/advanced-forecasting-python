{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "known-algeria",
   "metadata": {},
   "source": [
    "# Chapter 16 - Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-colorado",
   "metadata": {},
   "source": [
    "## Listing 16-1. Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "\n",
    "uri = \"https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip\"\n",
    "zip_path = keras.utils.get_file(origin=uri, fname=\"jena_climate_2009_2016.csv.zip\")\n",
    "zip_file = ZipFile(zip_path)\n",
    "zip_file.extractall()\n",
    "csv_path = \"jena_climate_2009_2016.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "del zip_file\n",
    "\n",
    "df = df.drop('Date Time', axis=1)\n",
    "cols = ['p',  'T', 'Tpot', 'Tdew', 'rh', 'VPmax', 'VPact', 'VPdef', 'sh', 'H2OC', 'rho', 'wv', 'mwv', 'wd']\n",
    "df.columns = cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-finance",
   "metadata": {},
   "source": [
    "## Listing 16-2. Creating the lagged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-surname",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.loc[2*72:,'T']\n",
    "lagged_x = []\n",
    "for lag in range(72,2*72,12):\n",
    "  lagged = df.shift(lag)\n",
    "  lagged.columns = [x + '.lag' + str(lag) for x in lagged.columns]\n",
    "  lagged_x.append(lagged)\n",
    "\n",
    "df = pd.concat(lagged_x, axis=1)\n",
    "df = df.iloc[2*72:,:] #drop missing values due to lags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-contract",
   "metadata": {},
   "source": [
    "## Listing 16-3. Fitting the MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-asian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a min max scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df = pd.DataFrame(scaler.fit_transform(df), columns = df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-masters",
   "metadata": {},
   "source": [
    "## Listing 16-3. Fitting the full PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-balloon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a PCA with maximum number of components\n",
    "from sklearn.decomposition import PCA\n",
    "mypca = PCA()\n",
    "mypca.fit(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-housing",
   "metadata": {},
   "source": [
    "## Listing 16-4. Fitting the full PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-parks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a scree plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(mypca.explained_variance_ratio_)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-vermont",
   "metadata": {},
   "source": [
    "## Listing 16-5. Fitting the PCA with 10 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-zealand",
   "metadata": {},
   "outputs": [],
   "source": [
    "mypca = PCA(10)\n",
    "df = mypca.fit_transform(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-overhead",
   "metadata": {},
   "source": [
    "## Listing 16-6. Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-running",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-dispute",
   "metadata": {},
   "source": [
    "## Listing 16-7. Specify the model and its architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-princess",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "simple_model = Sequential([\n",
    "  Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "  Dense(64, activation='relu'),\n",
    "  Dense(1),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-discrimination",
   "metadata": {},
   "source": [
    "## Listing 16-8. Obtain a summary of the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-draft",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-romantic",
   "metadata": {},
   "source": [
    "## Listing 16-9. Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-central",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model.compile(\n",
    "  optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mean_absolute_error'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-arrival",
   "metadata": {},
   "source": [
    "## Listing 16-10. Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-draft",
   "metadata": {},
   "outputs": [],
   "source": [
    "smod_history = simple_model.fit(X_train, y_train,\n",
    "          validation_split=0.2,\n",
    "          epochs=10,\n",
    "          batch_size=32,\n",
    "          shuffle = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-accreditation",
   "metadata": {},
   "source": [
    "## Listing 16-11. Plot the training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-cincinnati",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(smod_history.history['loss'])\n",
    "plt.plot(smod_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-examination",
   "metadata": {},
   "source": [
    "## Listing 16-12. A better architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-middle",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "model = Sequential([\n",
    "  Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "  Dense(256, activation='relu'),\n",
    "  Dense(256, activation='relu'),\n",
    "  Dense(256, activation='relu'),\n",
    "  Dense(256, activation='relu'),\n",
    "  Dense(256, activation='relu'),\n",
    "  Dense(256, activation='relu'),\n",
    "  Dense(256, activation='relu'),\n",
    "  Dense(256, activation='relu'),\n",
    "  Dense(256, activation='relu'),\n",
    "  Dense(256, activation='relu'),\n",
    "  Dense(256, activation='relu'),\n",
    "  Dense(256, activation='relu'),\n",
    "  Dense(256, activation='relu'),\n",
    "  Dense(256, activation='relu'),\n",
    "  Dense(256, activation='relu'),\n",
    "  Dense(256, activation='relu'),\n",
    "  Dense(256, activation='relu'),\n",
    "  Dense(256, activation='relu'),\n",
    "  Dense(256, activation='relu'),\n",
    "  Dense(1), ])\n",
    "model.compile(\n",
    "  optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mean_absolute_error'],\n",
    ")\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "          #validation_data=(X_test, y_test),\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=32,\n",
    "          shuffle = True\n",
    ")\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "print(r2_score(preds, y_test))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
